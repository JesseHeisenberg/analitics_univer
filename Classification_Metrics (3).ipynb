{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6c293e",
   "metadata": {},
   "source": "# Основные метрики классификации\n"
  },
  {
   "cell_type": "markdown",
   "id": "3b0ce0d3",
   "metadata": {},
   "source": [
    "## 1. Введение\n",
    "Оценка качества модели классификации — важный этап анализа данных. Выбор метрики зависит от задач и особенностей данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd42906",
   "metadata": {},
   "source": [
    "## 2. Импорт библиотек\n",
    "Сначала импортируем библиотеки, которые нам понадобятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf853510",
   "metadata": {},
   "source": [
    "## 3. Генерация данных и обучение модели\n",
    "Для демонстрации создадим синтетические данные и обучим логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание данных\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Вероятности положительного класса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53735f7f",
   "metadata": {},
   "source": [
    "## 4. Accuracy (Точность классификации)\n",
    "Точность — это доля правильно классифицированных примеров:\n",
    "\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
    "\n",
    "- **Нюанс**: Accuracy не подходит для несбалансированных данных, так как модель может предсказывать только один класс и получать высокую точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35fd14",
   "metadata": {},
   "source": [
    "## 5. Precision и Recall (Точность и полнота)\n",
    "- **Precision (Точность)** показывает, сколько из предсказанных положительных классов действительно положительные:\n",
    "  $$ Precision = \\frac{TP}{TP + FP} $$\n",
    "- **Recall (Полнота)** показывает, сколько истинных положительных классов модель нашла:\n",
    "  $$ Recall = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "**Когда использовать:**\n",
    "- Precision важен, когда ложные срабатывания (FP) критичны (например, в спам-фильтрах).\n",
    "- Recall важен, когда важно находить все положительные случаи (например, при диагностике болезней)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cb384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет precision и recall\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcb111",
   "metadata": {},
   "source": [
    "## 6. F1-Score (Гармоническое среднее Precision и Recall)\n",
    "F1-score учитывает и Precision, и Recall:\n",
    "$$ F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall} $$\n",
    "\n",
    "**Когда использовать:**\n",
    "- Если Accuracy не подходит из-за несбалансированных данных.\n",
    "- Если важно учитывать баланс между Precision и Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1-Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29182e",
   "metadata": {},
   "source": [
    "## 7. Матрица ошибок (Confusion Matrix)\n",
    "Матрица ошибок показывает количество TP, TN, FP и FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение матрицы ошибок\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7656fb0",
   "metadata": {},
   "source": [
    "## 8. ROC AUC Score (Площадь под ROC-кривой)\n",
    "ROC AUC измеряет, насколько хорошо модель различает классы. Чем ближе к 1, тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831abb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f'ROC AUC Score: {roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a494009",
   "metadata": {},
   "source": [
    "## 9. Итоговый отчет о классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод полного отчета\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c517825",
   "metadata": {},
   "source": [
    "## 10. Упражнения\n",
    "Попробуйте выполнить следующие задачи самостоятельно:\n",
    "1. Сгенерируйте несбалансированные данные и сравните Precision и Recall.\n",
    "2. Нарисуйте ROC-кривую для модели.\n",
    "3. Измените порог классификации (по умолчанию 0.5) и посмотрите, как меняются метрики."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 1. Генерация несбалансированных данных\n",
    "X, y = make_classification(n_samples=1000, n_features=10, weights=[0.9, 0.1], random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Вероятности положительного класса\n",
    "\n",
    "# Precision и Recall на несбалансированных данных\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.2f}, Recall: {recall:.2f}')\n",
    "\n",
    "# 2. Построение ROC-кривой\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc:.2f}', color='blue')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "da9242f0b3f5dcac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. Изменение порога классификации\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    precision_thresh = precision_score(y_test, y_pred_thresh)\n",
    "    recall_thresh = recall_score(y_test, y_pred_thresh)\n",
    "    print(f'Порог: {thresh:.1f} | Precision: {precision_thresh:.2f} | Recall: {recall_thresh:.2f}')\n",
    "\n",
    "# Итоговый отчет\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "id": "be2cd03ba960f557"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
