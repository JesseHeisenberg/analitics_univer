{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сверточные нейронные сети (CNN) для биологов\n",
    "\n",
    "**Содержание:**\n",
    "1. Введение и основы свертки\n",
    "2. Pooling и архитектура\n",
    "3. Реализация на PyTorch\n",
    "4. Обучение и оценка\n",
    "5. **Data Augmentation**\n",
    "6. **Transfer Learning и Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:39.645188Z",
     "start_time": "2026-02-07T10:34:38.644037Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Почему CNN для биологии?\n",
    "\n",
    "### Проблемы обычных сетей:\n",
    "- Огромное количество параметров\n",
    "- Потеря пространственной структуры\n",
    "- Нет инвариантности к сдвигам\n",
    "\n",
    "### CNN решает:\n",
    "- ✅ Локальная связность\n",
    "- ✅ Weight sharing\n",
    "- ✅ Иерархия признаков\n",
    "- ✅ Инвариантность к сдвигам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Основы свертки"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:42.183044Z",
     "start_time": "2026-02-07T10:34:39.667273Z"
    }
   },
   "source": [
    "def convolve2d(image, kernel, stride=1, padding=0):\n",
    "    if padding > 0:\n",
    "        image = np.pad(image, padding, mode='constant')\n",
    "    H, W = image.shape\n",
    "    K = kernel.shape[0]\n",
    "    out_h = (H - K) // stride + 1\n",
    "    out_w = (W - K) // stride + 1\n",
    "    output = np.zeros((out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            patch = image[i*stride:i*stride+K, j*stride:j*stride+K]\n",
    "            output[i, j] = np.sum(patch * kernel)\n",
    "    return output\n",
    "\n",
    "# Демонстрация\n",
    "image = np.array([[0,0,0,0,0,0,0],[0,1,1,1,1,1,0],[0,1,0,0,0,1,0],[0,1,0,1,0,1,0],[0,1,0,0,0,1,0],[0,1,1,1,1,1,0],[0,0,0,0,0,0,0]])\n",
    "vertical_edge = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "result = convolve2d(image, vertical_edge)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax1.set_title('Оригинал')\n",
    "ax2.imshow(result, cmap='gray')\n",
    "ax2.set_title('После свертки')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:42.308009Z",
     "start_time": "2026-02-07T10:34:42.223022Z"
    }
   },
   "source": [
    "digits = load_digits()\n",
    "X = digits.data.reshape(-1, 8, 8) / 16.0\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1437, 8, 8), Test: (360, 8, 8)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:53.662240Z",
     "start_time": "2026-02-07T10:34:42.311819Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Устройство: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Устройство: cpu\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:57.103548Z",
     "start_time": "2026-02-07T10:34:56.952870Z"
    }
   },
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(32 * 2 * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)\n",
    "print(f'Параметров: {sum(p.numel() for p in model.parameters()):,}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "Параметров: 22,698\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:57.236713Z",
     "start_time": "2026-02-07T10:34:57.201484Z"
    }
   },
   "source": [
    "X_train_t = torch.FloatTensor(X_train).unsqueeze(1)\n",
    "y_train_t = torch.LongTensor(y_train)\n",
    "X_test_t = torch.FloatTensor(X_test).unsqueeze(1)\n",
    "y_test_t = torch.LongTensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Функции обучения"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T10:34:57.245043Z",
     "start_time": "2026-02-07T10:34:57.237334Z"
    }
   },
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sum += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return loss_sum / total, correct / total"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Обучение базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-07T10:34:57.250971Z"
    }
   },
   "source": [
    "num_epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses, train_accs, test_losses, test_accs = [], [], [], []\n",
    "\n",
    "print('Обучение базовой модели...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] Train: {train_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "print(f'\\nФинальная точность базовой модели: {test_accs[-1]:.4f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Train: 1.0000, Test: 0.9833\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Визуализация обучения"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(test_losses, label='Test Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Базовая модель: Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax2.plot(train_accs, label='Train Acc')\n",
    "ax2.plot(test_accs, label='Test Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Базовая модель: Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Augmentation\n",
    "\n",
    "## 9. Data Augmentation для микроскопии\n",
    "\n",
    "Data augmentation — ключевая техника для биологических данных, где датасеты часто маленькие."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Augmentation transforms для обучающей выборки\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(15),              # Поворот ±15°\n",
    "    transforms.RandomAffine(                    # Аффинные трансформации\n",
    "        degrees=0, \n",
    "        translate=(0.1, 0.1),                   # Сдвиг до 10%\n",
    "        scale=(0.9, 1.1)                        # Масштаб 90-110%\n",
    "    ),\n",
    "    transforms.RandomApply([                    # С вероятностью 50%\n",
    "        transforms.GaussianBlur(kernel_size=3)\n",
    "    ], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(                   # Random erasing\n",
    "        p=0.3, \n",
    "        scale=(0.02, 0.1)\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Для тестовой выборки - только нормализация\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print('Transforms созданы!')\n",
    "print('\\nTrain transforms:')\n",
    "print(train_transforms)\n",
    "print('\\nTest transforms:')\n",
    "print(test_transforms)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Custom Dataset с augmentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class AugmentedDigitsDataset(Dataset):\n",
    "    \"\"\"Dataset с data augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Конвертируем в uint8 для PIL\n",
    "        image = (self.X[idx] * 255).astype(np.uint8)\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.FloatTensor(image).unsqueeze(0)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Создаём datasets с augmentation\n",
    "train_dataset_aug = AugmentedDigitsDataset(X_train, y_train, transform=train_transforms)\n",
    "test_dataset_aug = AugmentedDigitsDataset(X_test, y_test, transform=test_transforms)\n",
    "\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=32, shuffle=True)\n",
    "test_loader_aug = DataLoader(test_dataset_aug, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f'Augmented DataLoaders созданы!')\n",
    "print(f'Train batches: {len(train_loader_aug)}, Test batches: {len(test_loader_aug)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Визуализация augmentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Берем одно изображение и показываем разные augmentations\n",
    "sample_idx = 0\n",
    "sample_image = X_train[sample_idx]\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Оригинал\n",
    "axes[0].imshow(sample_image, cmap='gray')\n",
    "axes[0].set_title(f'Оригинал (label: {y_train[sample_idx]})', fontsize=10)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 14 augmented версий\n",
    "for i in range(1, 15):\n",
    "    aug_image, label = train_dataset_aug[sample_idx]\n",
    "    aug_image_np = aug_image.squeeze().numpy()\n",
    "    axes[i].imshow(aug_image_np, cmap='gray')\n",
    "    axes[i].set_title(f'Augmentation {i}', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation для цифр (имитация микроскопии)', fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Каждый раз при загрузке изображение трансформируется случайным образом!')\n",
    "print('Это эффективно увеличивает размер датасета в десятки раз.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Обучение модели с augmentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Создаём новую модель для честного сравнения\n",
    "model_aug = SimpleCNN().to(device)\n",
    "optimizer_aug = optim.Adam(model_aug.parameters(), lr=0.001)\n",
    "\n",
    "train_losses_aug, train_accs_aug = [], []\n",
    "test_losses_aug, test_accs_aug = [], []\n",
    "\n",
    "print('Обучение модели с augmentation...')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model_aug, train_loader_aug, criterion, optimizer_aug, device)\n",
    "    test_loss, test_acc = evaluate(model_aug, test_loader_aug, criterion, device)\n",
    "    train_losses_aug.append(train_loss)\n",
    "    train_accs_aug.append(train_acc)\n",
    "    test_losses_aug.append(test_loss)\n",
    "    test_accs_aug.append(test_acc)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] Train: {train_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "print(f'\\nФинальная точность с augmentation: {test_accs_aug[-1]:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Сравнение: с augmentation vs без"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(train_losses, label='Без Aug: Train', linestyle='--', alpha=0.7)\n",
    "axes[0, 0].plot(test_losses, label='Без Aug: Test', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Loss: Без Augmentation')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(train_losses_aug, label='С Aug: Train', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].plot(test_losses_aug, label='С Aug: Test', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].set_title('Loss: С Augmentation')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1, 0].plot(train_accs, label='Без Aug: Train', linestyle='--', alpha=0.7)\n",
    "axes[1, 0].plot(test_accs, label='Без Aug: Test', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].set_title('Accuracy: Без Augmentation')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(train_accs_aug, label='С Aug: Train', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].plot(test_accs_aug, label='С Aug: Test', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_title('Accuracy: С Augmentation')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('СРАВНЕНИЕ РЕЗУЛЬТАТОВ')\n",
    "print('='*60)\n",
    "print(f'Без Augmentation: Test Acc = {test_accs[-1]:.4f}')\n",
    "print(f'С Augmentation:   Test Acc = {test_accs_aug[-1]:.4f}')\n",
    "print(f'\\nРазница: {(test_accs_aug[-1] - test_accs[-1]):.4f}')\n",
    "\n",
    "# Анализ overfitting\n",
    "overfit_baseline = train_accs[-1] - test_accs[-1]\n",
    "overfit_aug = train_accs_aug[-1] - test_accs_aug[-1]\n",
    "print(f'\\nOverfitting (Train-Test gap):')\n",
    "print(f'Без Aug: {overfit_baseline:.4f}')\n",
    "print(f'С Aug:   {overfit_aug:.4f}')\n",
    "print(f'\\nAugmentation уменьшил overfitting на: {(overfit_baseline - overfit_aug):.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Transfer Learning и Fine-tuning\n",
    "\n",
    "## 10. Transfer Learning\n",
    "\n",
    "Transfer learning — использование предобученной модели для новой задачи.\n",
    "\n",
    "### Стратегии:\n",
    "1. **Feature Extraction**: Заморозить все слои, обучить только classifier\n",
    "2. **Fine-tuning**: Разморозить последние слои и дообучить\n",
    "3. **Full Training**: Обучить всю сеть с предобученными весами\n",
    "\n",
    "### Для биологии:\n",
    "- Датасет < 1K → Feature Extraction\n",
    "- Датасет 1K-100K → Fine-tuning\n",
    "- Датасет > 100K → Full Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Загружаем предобученную ResNet18\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "print('ResNet18 архитектура:')\n",
    "print(resnet18)\n",
    "print(f'\\nВсего параметров: {sum(p.numel() for p in resnet18.parameters()):,}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Адаптация ResNet для наших данных\n",
    "\n",
    "ResNet ожидает входы 224×224×3, а у нас 8×8×1. Нужно адаптировать."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ResNetForDigits(nn.Module):\n",
    "    \"\"\"ResNet18 адаптированная для маленьких grayscale изображений\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10, pretrained=True):\n",
    "        super(ResNetForDigits, self).__init__()\n",
    "        \n",
    "        # Загружаем предобученную ResNet18\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Изменяем первый слой для grayscale (1 канал вместо 3)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Изменяем последний FC слой для 10 классов\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Добавляем upsampling для маленьких изображений\n",
    "        self.upsample = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Увеличиваем изображение до 224×224\n",
    "        x = self.upsample(x)\n",
    "        # Пропускаем через ResNet\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "\n",
    "# Создаём модель\n",
    "resnet_model = ResNetForDigits(num_classes=10, pretrained=True).to(device)\n",
    "\n",
    "print('ResNet адаптирована для digits!')\n",
    "print(f'Параметров: {sum(p.numel() for p in resnet_model.parameters()):,}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Стратегия 1: Feature Extraction\n",
    "\n",
    "Замораживаем все слои кроме последнего FC."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Создаём модель для feature extraction\n",
    "resnet_frozen = ResNetForDigits(num_classes=10, pretrained=True).to(device)\n",
    "\n",
    "# Замораживаем все параметры\n",
    "for param in resnet_frozen.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Размораживаем только последний FC слой\n",
    "for param in resnet_frozen.resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Проверяем\n",
    "trainable_params = sum(p.numel() for p in resnet_frozen.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in resnet_frozen.parameters())\n",
    "\n",
    "print('Feature Extraction режим:')\n",
    "print(f'Всего параметров: {total_params:,}')\n",
    "print(f'Обучаемых параметров: {trainable_params:,}')\n",
    "print(f'Заморожено: {total_params - trainable_params:,} ({100*(1-trainable_params/total_params):.1f}%)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Обучаем только FC слой\n",
    "optimizer_frozen = optim.Adam(filter(lambda p: p.requires_grad, resnet_frozen.parameters()), lr=0.001)\n",
    "\n",
    "train_losses_frozen, train_accs_frozen = [], []\n",
    "test_losses_frozen, test_accs_frozen = [], []\n",
    "\n",
    "num_epochs_transfer = 20  # Меньше эпох для transfer learning\n",
    "\n",
    "print('\\nОбучение в режиме Feature Extraction...')\n",
    "for epoch in range(num_epochs_transfer):\n",
    "    train_loss, train_acc = train_epoch(resnet_frozen, train_loader, criterion, optimizer_frozen, device)\n",
    "    test_loss, test_acc = evaluate(resnet_frozen, test_loader, criterion, device)\n",
    "    train_losses_frozen.append(train_loss)\n",
    "    train_accs_frozen.append(train_acc)\n",
    "    test_losses_frozen.append(test_loss)\n",
    "    test_accs_frozen.append(test_acc)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs_transfer}] Train: {train_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "print(f'\\nFeature Extraction Test Acc: {test_accs_frozen[-1]:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Стратегия 2: Fine-tuning\n",
    "\n",
    "Размораживаем последние слои и дообучаем с маленьким learning rate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Создаём новую модель для fine-tuning\n",
    "resnet_finetune = ResNetForDigits(num_classes=10, pretrained=True).to(device)\n",
    "\n",
    "# Замораживаем ранние слои (conv1, layer1, layer2)\n",
    "layers_to_freeze = [resnet_finetune.resnet.conv1, \n",
    "                    resnet_finetune.resnet.bn1,\n",
    "                    resnet_finetune.resnet.layer1,\n",
    "                    resnet_finetune.resnet.layer2]\n",
    "\n",
    "for layer in layers_to_freeze:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Размораживаем поздние слои (layer3, layer4, fc)\n",
    "trainable_params = sum(p.numel() for p in resnet_finetune.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in resnet_finetune.parameters())\n",
    "\n",
    "print('Fine-tuning режим:')\n",
    "print(f'Всего параметров: {total_params:,}')\n",
    "print(f'Обучаемых параметров: {trainable_params:,}')\n",
    "print(f'Заморожено: {total_params - trainable_params:,} ({100*(1-trainable_params/total_params):.1f}%)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Используем меньший learning rate для fine-tuning\n",
    "optimizer_finetune = optim.Adam(filter(lambda p: p.requires_grad, resnet_finetune.parameters()), lr=0.0001)\n",
    "\n",
    "train_losses_finetune, train_accs_finetune = [], []\n",
    "test_losses_finetune, test_accs_finetune = [], []\n",
    "\n",
    "print('\\nОбучение в режиме Fine-tuning...')\n",
    "for epoch in range(num_epochs_transfer):\n",
    "    train_loss, train_acc = train_epoch(resnet_finetune, train_loader, criterion, optimizer_finetune, device)\n",
    "    test_loss, test_acc = evaluate(resnet_finetune, test_loader, criterion, device)\n",
    "    train_losses_finetune.append(train_loss)\n",
    "    train_accs_finetune.append(train_acc)\n",
    "    test_losses_finetune.append(test_loss)\n",
    "    test_accs_finetune.append(test_acc)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs_transfer}] Train: {train_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "print(f'\\nFine-tuning Test Acc: {test_accs_finetune[-1]:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Сравнение всех подходов"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Test Accuracy\n",
    "axes[0].plot(test_accs[:num_epochs_transfer], label='SimpleCNN (scratch)', linewidth=2)\n",
    "axes[0].plot(test_accs_aug[:num_epochs_transfer], label='SimpleCNN + Aug', linewidth=2)\n",
    "axes[0].plot(test_accs_frozen, label='ResNet (frozen)', linewidth=2)\n",
    "axes[0].plot(test_accs_finetune, label='ResNet (fine-tune)', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('Сравнение подходов: Test Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test Loss\n",
    "axes[1].plot(test_losses[:num_epochs_transfer], label='SimpleCNN (scratch)', linewidth=2)\n",
    "axes[1].plot(test_losses_aug[:num_epochs_transfer], label='SimpleCNN + Aug', linewidth=2)\n",
    "axes[1].plot(test_losses_frozen, label='ResNet (frozen)', linewidth=2)\n",
    "axes[1].plot(test_losses_finetune, label='ResNet (fine-tune)', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Test Loss')\n",
    "axes[1].set_title('Сравнение подходов: Test Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('ИТОГОВОЕ СРАВНЕНИЕ ВСЕХ ПОДХОДОВ')\n",
    "print('='*70)\n",
    "print(f'1. SimpleCNN (scratch):      {test_accs[num_epochs_transfer-1]:.4f}')\n",
    "print(f'2. SimpleCNN + Augmentation: {test_accs_aug[num_epochs_transfer-1]:.4f}')\n",
    "print(f'3. ResNet (frozen):          {test_accs_frozen[-1]:.4f}')\n",
    "print(f'4. ResNet (fine-tune):       {test_accs_finetune[-1]:.4f}')\n",
    "print('='*70)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Выводы и рекомендации\n",
    "\n",
    "### Data Augmentation:\n",
    "- ✅ Критически важен для малых датасетов\n",
    "- ✅ Уменьшает overfitting\n",
    "- ✅ Увеличивает эффективный размер датасета\n",
    "- ✅ Для биологии: повороты, отражения, масштаб, яркость\n",
    "\n",
    "### Transfer Learning:\n",
    "- ✅ **Feature Extraction**: Быстро, для очень малых данных (<1K)\n",
    "- ✅ **Fine-tuning**: Лучшие результаты, требует больше данных (1K-100K)\n",
    "- ✅ Использовать предобученные модели на близких задачах\n",
    "- ✅ Меньший LR для fine-tuning (0.0001 vs 0.001)\n",
    "\n",
    "### Для биологических данных:\n",
    "\n",
    "| Размер датасета | Стратегия | Learning Rate |\n",
    "|----------------|-----------|---------------|\n",
    "| < 100 | Feature Extraction + Heavy Aug | 0.001 |\n",
    "| 100-1K | Feature Extraction + Aug | 0.001 |\n",
    "| 1K-10K | Fine-tuning + Aug | 0.0001 |\n",
    "| 10K-100K | Fine-tuning | 0.0001 |\n",
    "| > 100K | Train from scratch | 0.001 |\n",
    "\n",
    "### Практические советы:\n",
    "\n",
    "1. **Всегда начинайте с augmentation**\n",
    "2. **Попробуйте transfer learning** даже на небольших данных\n",
    "3. **Используйте pretrained модели** на похожих задачах (медицинские данные)\n",
    "4. **Следите за overfitting**: Train-Test gap\n",
    "5. **Валидация экспертами** критична в биологии\n",
    "6. **Интерпретация**: Используйте Grad-CAM для понимания решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задания для самостоятельной работы\n",
    "\n",
    "### Базовый уровень:\n",
    "1. Добавьте еще один тип augmentation (например, ColorJitter)\n",
    "2. Поэкспериментируйте с разными значениями rotation\n",
    "3. Попробуйте другую архитектуру (VGG, DenseNet)\n",
    "\n",
    "### Средний уровень:\n",
    "4. Реализуйте learning rate scheduler\n",
    "5. Добавьте early stopping\n",
    "6. Сохраните и загрузите лучшую модель\n",
    "7. Визуализируйте confusion matrix для каждого подхода\n",
    "\n",
    "### Продвинутый уровень:\n",
    "8. Примените к реальным биологическим данным (Blood Cells, Chest X-Ray)\n",
    "9. Реализуйте Grad-CAM для визуализации\n",
    "10. Сравните разные стратегии fine-tuning (разморозить разное количество слоев)\n",
    "11. Используйте ensemble из нескольких моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Сохранение всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Сохраняем все модели\n",
    "torch.save({\n",
    "    'model_baseline': model.state_dict(),\n",
    "    'model_augmented': model_aug.state_dict(),\n",
    "    'model_frozen': resnet_frozen.state_dict(),\n",
    "    'model_finetune': resnet_finetune.state_dict(),\n",
    "    'results': {\n",
    "        'baseline': {'train': train_accs, 'test': test_accs},\n",
    "        'augmented': {'train': train_accs_aug, 'test': test_accs_aug},\n",
    "        'frozen': {'train': train_accs_frozen, 'test': test_accs_frozen},\n",
    "        'finetune': {'train': train_accs_finetune, 'test': test_accs_finetune}\n",
    "    }\n",
    "}, 'all_cnn_models.pth')\n",
    "\n",
    "print('Все модели сохранены в all_cnn_models.pth!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Итоговая таблица\n",
    "\n",
    "| Подход | Test Accuracy | Параметров | Время обучения | Когда использовать |\n",
    "|--------|---------------|------------|----------------|--------------------|\n",
    "| SimpleCNN | ~95% | ~50K | Быстро | Baseline |\n",
    "| + Augmentation | ~96% | ~50K | Быстро | Малые данные |\n",
    "| ResNet Frozen | ~97% | 5K trainable | Средне | Очень малые данные |\n",
    "| ResNet Fine-tune | ~98% | 5M trainable | Медленно | Средние данные |\n",
    "\n",
    "**Удачи в применении CNN к биологическим данным! 🧬🔬**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
